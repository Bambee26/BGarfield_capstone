import pandas as pd
from sklearn.impute import SimpleImputer

def handle_missing_data(input_csv_file_path, output_cleaned_csv_file_path, output_missing_csv_file_path):
    # Load the CSV file into a DataFrame
    df = pd.read_csv(input_csv_file_path)
    
    # Convert diagnosis column to binary (0 for 'B', 1 for 'M')
    df['diagnosis'] = df['diagnosis'].apply(lambda x: 0 if x == 'B' else 1 if x == 'M' else x)
    
    # Drop columns with all missing values
    df.dropna(axis=1, how='all', inplace=True)
    
    # Separate rows with any missing values
    rows_with_missing = df[df.isnull().any(axis=1)]
    rows_with_missing.to_csv(output_missing_csv_file_path, index=False)
    
    # Drop rows with any missing values from the original DataFrame
    df_clean = df.dropna()

    # Check if there are any missing values in the cleaned DataFrame
    if df_clean.isnull().values.any():
        # Identify numerical and categorical columns
        numerical_cols = df_clean.select_dtypes(include=['number']).columns
        categorical_cols = df_clean.select_dtypes(include=['object']).columns
        
        # Impute missing values in numerical columns with the mean
        if len(numerical_cols) > 0:
            imputer_num = SimpleImputer(strategy='mean')
            df_clean[numerical_cols] = imputer_num.fit_transform(df_clean[numerical_cols])
        
        # Impute missing values in categorical columns with the most frequent value (mode)
        if len(categorical_cols) > 0:
            imputer_cat = SimpleImputer(strategy='most_frequent')
            df_clean[categorical_cols] = imputer_cat.fit_transform(df_clean[categorical_cols])
        
        print(f"Missing values found and handled. Cleaned data saved to '{output_cleaned_csv_file_path}'.")
    else:
        print("No missing values found in the cleaned data. No changes made.")
    
    # Save the cleaned DataFrame to a new CSV file
    df_clean.to_csv(output_cleaned_csv_file_path, index=False)
    
    return output_cleaned_csv_file_path, output_missing_csv_file_path

# Example usage
input_csv_file_path = 'data.csv'
output_cleaned_csv_file_path = 'cleaned_data.csv'
output_missing_csv_file_path = 'missing_data.csv'
cleaned_file, missing_file = handle_missing_data(input_csv_file_path, output_cleaned_csv_file_path, output_missing_csv_file_path)

# Output the paths to the cleaned and missing CSV files
print(f"Cleaned data is saved in: {cleaned_file}")
print(f"Rows with missing data are saved in: {missing_file}")

import pandas as pd

def identify_outliers_iqr(df):
    """
    Identify outliers using the Interquartile Range (IQR) method.
    
    Parameters:
    - df: Pandas DataFrame
    
    Returns:
    - outliers: Dictionary where keys are column names and values are lists of outlier indices
    """
    outliers = {}
    
    # Calculate Q1 (25th percentile) and Q3 (75th percentile) for each column
    Q1 = df.quantile(0.25)
    Q3 = df.quantile(0.75)
    
    # Calculate IQR for each column
    IQR = Q3 - Q1
    
    # Define threshold for outliers (typically 1.5 times the IQR)
    threshold = 1.5
    
    # Identify outliers for each column
    for col in df.columns:
        lower_bound = Q1[col] - threshold * IQR[col]
        upper_bound = Q3[col] + threshold * IQR[col]
        outliers[col] = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index.tolist()
    
    return outliers

# Example usage
input_csv_file = 'cleaned_data.csv'
df = pd.read_csv(input_csv_file)

# Identify outliers using IQR method
outliers = identify_outliers_iqr(df)

# Display outliers found
for col, idx in outliers.items():
    print(f"Outliers in column '{col}':")
    print(df.loc[idx])
    print("\n")
